{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear boundaries ##\n",
    "\n",
    "### boundary: a line ###\n",
    "\n",
    "$w_1x_1 + w_2x_2 + b = 0$  \n",
    "\n",
    "$Wx + b = 0$  \n",
    "\n",
    "$W = (w_1, w_2)$  \n",
    "\n",
    "$x = (x_1, x_2)$  \n",
    "\n",
    "$y =$ label: 0 or 1  \n",
    "\n",
    "<img src=\"p1.png\" width=500>\n",
    "\n",
    "### prediction ###\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\left\\{ \\begin{array}{rl}\n",
    " 1&\\mbox{if $Wx + b > 0$} \\\\\n",
    "  0&\\mbox{if $Wx + b < 0$}\n",
    "       \\end{array} \\right.\n",
    "$$\n",
    "\n",
    "### goal ###\n",
    "to model $\\hat{y}$ as close to $y$ as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boundary: a plane ###\n",
    "\n",
    "$w_1x_1 + w_2x_2 + w_3x_3 + b = 0$  \n",
    "\n",
    "$Wx + b = 0$  \n",
    "\n",
    "$W = (w_1, w_2, w_3)$  \n",
    "\n",
    "$x = (x_1, x_2, x_3)$  \n",
    "\n",
    "$y =$ label: 0 or 1  \n",
    "\n",
    "<img src=\"p2.png\" width=500>\n",
    "\n",
    "### prediction ###\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\left\\{ \\begin{array}{rl}\n",
    " 1&\\mbox{if $Wx + b > 0$} \\\\\n",
    "  0&\\mbox{if $Wx + b < 0$}\n",
    "       \\end{array} \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boundary: an n-1 dimensional space ###\n",
    "\n",
    "$w_1x_1 + w_2x_2 + ... + w_nx_n + b = 0$  \n",
    "\n",
    "$Wx + b = 0$  \n",
    "\n",
    "$W = (w_1, w_2, ..., w_n)$  \n",
    "\n",
    "$x = (x_1, x_2, ..., x_n)$  \n",
    "\n",
    "$y =$ label: 0 or 1  \n",
    "\n",
    "<img src=\"p3.png\" width=500>\n",
    "\n",
    "### prediction ###\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\left\\{ \\begin{array}{rl}\n",
    " 1&\\mbox{if $Wx + b > 0$} \\\\\n",
    "  0&\\mbox{if $Wx + b < 0$}\n",
    "       \\end{array} \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src=\"p4.png\" width=500>\n",
    "\n",
    "<img src=\"p5.png\" width=500>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"p6.png\" width=500>  \n",
    "\n",
    "<img src=\"p7.png\" width=500>  \n",
    "\n",
    "<img src=\"p8.png\" width=500>  \n",
    "\n",
    "<img src=\"p9.png\" width=500>  \n",
    "\n",
    "<img src=\"q1.png\" width=500>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptrons as Logical Operators ###  \n",
    "\n",
    "In this lesson, we'll see one of the many great applications of perceptrons. As logical operators! You'll have the chance to create the perceptrons for the most common of these, the AND, OR, and NOT operators. And then, we'll see what to do about the elusive XOR operator. Let's dive in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"middle\"><video width=\"100%\" controls><source src=\"v1.mp4\" type=\"video/mp4\"></video></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<div align=\"middle\"><video width=\"100%\" controls><source src=\"v1.mp4\" type=\"video/mp4\"></video></div>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AND logical operator perceptron ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      "Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "      1          1                   0.9                    1          Yes\n",
      "      1          0                  -0.1                    0          Yes\n",
      "      0          1                  -0.1                    0          Yes\n",
      "      0          0                  -1.1                    0          Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 1.0\n",
    "weight2 = 1.0\n",
    "bias = -1.1\n",
    "\n",
    "# Inputs and outputs\n",
    "test_inputs = [(1, 1), (1, 0), (0, 1), (0, 0)]\n",
    "correct_outputs = [True, False, False, False]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"q2.png\" width=600>\n",
    "\n",
    "### OR perceptron ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      "Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "      1          1                   1.1                    1          Yes\n",
      "      1          0                   0.1                    1          Yes\n",
      "      0          1                   0.1                    1          Yes\n",
      "      0          0                  -0.9                    0          Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = 1.0\n",
    "weight2 = 1.0\n",
    "bias = -0.9\n",
    "\n",
    "# Inputs and outputs\n",
    "test_inputs = [(1, 1), (1, 0), (0, 1), (0, 0)]\n",
    "correct_outputs = [True, True, True, False]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOT perceptron ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice!  You got it all correct.\n",
      "\n",
      "Input 1    Input 2    Linear Combination    Activation Output   Is Correct\n",
      "      0          0                   1.1                    1          Yes\n",
      "      0          1                  -0.1                    0          Yes\n",
      "      1          0                   0.0                    1          Yes\n",
      "      1          1                  -1.2                    0          Yes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# TODO: Set weight1, weight2, and bias\n",
    "weight1 = -1.1\n",
    "weight2 = -1.2\n",
    "bias = 1.1\n",
    "\n",
    "# Inputs and outputs\n",
    "test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "correct_outputs = [True, False, True, False]\n",
    "outputs = []\n",
    "\n",
    "# Generate and check output\n",
    "for test_input, correct_output in zip(test_inputs, correct_outputs):\n",
    "    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias\n",
    "    output = int(linear_combination >= 0)\n",
    "    is_correct_string = 'Yes' if output == correct_output else 'No'\n",
    "    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])\n",
    "\n",
    "# Print output\n",
    "num_wrong = len([output[4] for output in outputs if output[4] == 'No'])\n",
    "output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])\n",
    "if not num_wrong:\n",
    "    print('Nice!  You got it all correct.\\n')\n",
    "else:\n",
    "    print('You got {} wrong.  Keep trying!\\n'.format(num_wrong))\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR perceptron ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"middle\"><video width=\"100%\" controls><source src=\"v2.mp4\" type=\"video/mp4\"></video></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<div align=\"middle\"><video width=\"100%\" controls><source src=\"v2.mp4\" type=\"video/mp4\"></video></div>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build an XOR Multi-Layer Perceptron  \n",
    "\n",
    "Now, let's build a multi-layer perceptron from the AND, NOT, and OR perceptrons to create XOR logic!  \n",
    "\n",
    "The neural network below contains 3 perceptrons, A, B, and C. The last one (AND) has been given to you. The input to the neural network is from the first node. The output comes out of the last node.  \n",
    "\n",
    "The multi-layer perceptron below calculates XOR. Each perceptron is a logic operation of AND, OR, and NOT. However, the perceptrons A, B, and C don't indicate their operation. In the following quiz, set the correct operations for the perceptrons to calculate XOR.\n",
    "\n",
    "<img src=\"q3.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we introduce the NAND operator as the combination of AND and NOT, then we get the following two-layer perceptron that will model XOR. That's our first neural network!\n",
    "\n",
    "<img src=\"q4.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Trick ###  \n",
    "\n",
    "In the last section you used your logic and your mathematical knowledge to create perceptrons for some of the most common logical operators. In real life, though, we can't be building these perceptrons ourselves. The idea is that we give them the result, and they build themselves. For this, here's a pretty neat trick that will help us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"middle\"><video width=\"100%\" controls><source src=\"v3.mp4\" type=\"video/mp4\"></video></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<div align=\"middle\"><video width=\"100%\" controls><source src=\"v3.mp4\" type=\"video/mp4\"></video></div>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: CLOSER!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time for some math! ###  \n",
    "\n",
    "Now that we've learned that the points that are misclassified, want the line to move closer to them, let's do some math. The following video shows a mathematical trick that modifies the equation of the line, so that it comes closer to a particular point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"middle\"><video width=\"100%\" controls><source src=\"v4.mp4\" type=\"video/mp4\"></video></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<div align=\"middle\"><video width=\"100%\" controls><source src=\"v4.mp4\" type=\"video/mp4\"></video></div>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second example, where the line is described by 3x1+ 4x2 - 10 = 0, if the learning rate was set to 0.1, how many times would you have to apply the perceptron trick to move the line to a position where the blue point, at (1, 1), is correctly classified?\n",
    "\n",
    "1) 3.1 + 4.1 - 9.9 = -2.7  \n",
    "2) 3.2 + 4.2 - 9.8 = -2.4  \n",
    "3) 3.3 + 4.3 - 9.7 = -2.1  \n",
    "4) -1.8  \n",
    "5) -1.5  \n",
    "6) -1.2  \n",
    "7) -0.9  \n",
    "8) -0.6  \n",
    "9) -0.3  \n",
    "10) 0  \n",
    "\n",
    "### answer: 10 !! ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"middle\"><video width=\"100%\" controls><source src=\"v5.mp4\" type=\"video/mp4\"></video></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<div align=\"middle\"><video width=\"100%\" controls><source src=\"v5.mp4\" type=\"video/mp4\"></video></div>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding the Perceptron Algorithm ###  \n",
    "\n",
    "Time to code! In this quiz, you'll have the chance to implement the perceptron algorithm to separate the following data (given in the file data.csv).\n",
    "\n",
    "Recall that the perceptron step works as follows. For a point with coordinates $(p,q)$ label $y$, and prediction given by the equation  \n",
    "\n",
    "$\\hat{y} = step(w_1x_1 + w_2x_2 + b)$:\n",
    "\n",
    "If the point is correctly classified, do nothing.  \n",
    "\n",
    "If the point is classified positive, but it has a negative label, __subtract__ $\\alpha p$, $\\alpha q$, and $\\alpha$ from $w_1$, $w_2$, $b$ respectively.  \n",
    "\n",
    "If the point is classified negative, but it has a positive label, __add__ $\\alpha p$, $\\alpha q$,and $\\alpha$ to $w_1$,  $w_2$, and $b$ respectively.  \n",
    "\n",
    "Then click on test run to graph the solution that the perceptron algorithm gives you. It'll actually draw a set of dotted lines, that show how the algorithm approaches to the best solution, given by the black solid line.\n",
    "\n",
    "\n",
    "Feel free to play with the parameters of the algorithm (number of epochs, learning rate, and even the randomizing of the initial parameters) to see how your initial conditions can affect the solution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Setting the random seed, feel free to change it and see different solutions.\n",
    "np.random.seed(42)\n",
    "\n",
    "def stepFunction(t):\n",
    "    if t >= 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def prediction(X, W, b):\n",
    "    return stepFunction((np.matmul(X,W)+b)[0])\n",
    "\n",
    "# the code below implements the perceptron trick.\n",
    "# The function receive as inputs the data X, the labels y, the weights W (as an array), and the bias b,\n",
    "# updates the weights and bias W, b, according to the perceptron algorithm, and return W and b.\n",
    "def perceptronStep(X, y, W, b, learn_rate = 0.01):\n",
    "    for i in range(len(X)):\n",
    "        y_hat = prediction(X[i],W,b)\n",
    "        if y[i]-y_hat == 1:\n",
    "            W[0] += X[i][0]*learn_rate\n",
    "            W[1] += X[i][1]*learn_rate\n",
    "            b += learn_rate\n",
    "        elif y[i]-y_hat == -1:\n",
    "            W[0] -= X[i][0]*learn_rate\n",
    "            W[1] -= X[i][1]*learn_rate\n",
    "            b -= learn_rate\n",
    "    return W, b\n",
    "\n",
    "    \n",
    "# This function runs the perceptron algorithm repeatedly on the dataset,\n",
    "# and returns a few of the boundary lines obtained in the iterations,\n",
    "# for plotting purposes.\n",
    "# Feel free to play with the learning rate and the num_epochs,\n",
    "# and see your results plotted below.\n",
    "def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):\n",
    "    x_min, x_max = min(X.T[0]), max(X.T[0])\n",
    "    y_min, y_max = min(X.T[1]), max(X.T[1])\n",
    "    W = np.array(np.random.rand(2,1))\n",
    "    b = np.random.rand(1)[0] + x_max\n",
    "    # These are the solution lines that get plotted below.\n",
    "    boundary_lines = []\n",
    "    for i in range(num_epochs):\n",
    "        # In each epoch, we apply the perceptron step.\n",
    "        W, b = perceptronStep(X, y, W, b, learn_rate)\n",
    "        boundary_lines.append((-W[0]/W[1], -b/W[1]))\n",
    "    return boundary_lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"q6.png\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non-linear regions ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"middle\"><video width=\"100%\" controls><source src=\"v6.mp4\" type=\"video/mp4\"></video></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<div align=\"middle\"><video width=\"100%\" controls><source src=\"v6.mp4\" type=\"video/mp4\"></video></div>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log-loss error function :: Gradient Descent ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"middle\"><video width=\"100%\" controls><source src=\"v7.mp4\" type=\"video/mp4\"></video></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<div align=\"middle\"><video width=\"100%\" controls><source src=\"v7.mp4\" type=\"video/mp4\"></video></div>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete vs Continuous Predictions ###  \n",
    "\n",
    "In the last few videos, we learned that continuous error functions are better than discrete error functions, when it comes to optimizing. For this, we need to switch from discrete to continuous predictions. The next two videos will guide us in doing that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"middle\"><video width=\"100%\" controls><source src=\"v8.mp4\" type=\"video/mp4\"></video></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<div align=\"middle\"><video width=\"100%\" controls><source src=\"v8.mp4\" type=\"video/mp4\"></video></div>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"middle\"><video width=\"100%\" controls><source src=\"v9.mp4\" type=\"video/mp4\"></video></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<div align=\"middle\"><video width=\"100%\" controls><source src=\"v9.mp4\" type=\"video/mp4\"></video></div>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Function ###\n",
    "\n",
    "The sigmoid function is defined as: \n",
    "\n",
    "# $\\sigma(x) = \\frac{1}{1+e^{-x}}$ #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Class Classification and Softmax ###\n",
    "\n",
    "The Softmax Function  \n",
    "\n",
    "In the next video, we'll learn about the softmax function, which is the equivalent of the sigmoid activation function, but when the problem has 3 or more classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"middle\"><video width=\"100%\" controls><source src=\"v10.mp4\" type=\"video/mp4\"></video></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<div align=\"middle\"><video width=\"100%\" controls><source src=\"v10.mp4\" type=\"video/mp4\"></video></div>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"middle\"><video width=\"100%\" controls><source src=\"v11.mp4\" type=\"video/mp4\"></video></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<div align=\"middle\"><video width=\"100%\" controls><source src=\"v11.mp4\" type=\"video/mp4\"></video></div>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Function ###\n",
    "\n",
    "(normalizes all input values so they all add up to 1)\n",
    "\n",
    "The softmax function is defined as: \n",
    "\n",
    "Linear Function Scores: $Z_1, ..., Z_n$\n",
    "\n",
    "# $P($class $i) = \\frac{e^{Z_i}}{e^{Z_1}+ ... + e^{Z_n}}$ #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax in py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def softmax(L):\n",
    "    expL = np.exp(L)\n",
    "    sumExpL = sum(expL)\n",
    "    result = []\n",
    "    for i in expL:\n",
    "        result.append(i*1.0/sumExpL)\n",
    "    return result\n",
    "    \n",
    "    # Note: The function np.divide can also be used here, as follows:\n",
    "    # def softmax(L):\n",
    "    #     expL = np.exp(L)\n",
    "    #     return np.divide (expL, expL.sum())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
