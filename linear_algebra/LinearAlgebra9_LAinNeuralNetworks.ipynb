{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Neural Network? ###\n",
    "\n",
    "Neural networks is an important area of research in neuroscience. When we, as computer scientists, engineers, or other professionals outside the scope of pure neuroscience refer to neural networks, we actually mean artificial neural networks.\n",
    "\n",
    "The following is a fun short movie that will give you a nice visualization of these biological neural networks\n",
    "\n",
    "The design of the Artificial Neural Network was inspired by the biological one. The neurons used in the artificial network below are essentially mathematical functions.\n",
    "\n",
    "Each network has:\n",
    "\n",
    "Input neurons- which we refer to as the input layer of neurons\n",
    "Output neurons- which we refer to as the output layer of neurons\n",
    "and\n",
    "\n",
    "Internal neurons- which we refer to as the hidden layer of neurons. Each neural network can have many hidden layers\n",
    "The following picture is of a simple neural network with a single hidden layer.\n",
    "\n",
    "<img src=\"pic1.png\" width=400>\n",
    "\n",
    "This version of a simplified artificial neural network is comprised out of:\n",
    "\n",
    "An input vector $\\vec{x}=\\begin{bmatrix} x_1 & x_2 & x_3 & ... &x_n \\end{bmatrix}$ \n",
    "\n",
    "A hidden layer vector $\\vec{h}=\\begin{bmatrix} h_1 & h_2 & h_3 & ... &h_m \\end{bmatrix}$ and\n",
    "\n",
    "An output vector $\\vec{y}=\\begin{bmatrix} y_1 & y_2 & y_3 & ... &y_k \\end{bmatrix}$\n",
    "\n",
    "Each element in the vectors is a mathematical argument which we will elaborate on very soon.\n",
    "\n",
    "Notice that there is no connection between the number of inputs, number of hidden neurons in the hidden layer or number of outputs.\n",
    "\n",
    "(The notation we used here is of a row vector, these vectors can be expressed as column vectors as well)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Are The Neurons Connected? ###\n",
    "\n",
    "Let's go back to the picture above ^\n",
    "\n",
    "Notice the \"lines\" connecting the different neurons?\n",
    "\n",
    "In practice, these lines symbolize a coefficient (a scalar) that is mathematically connecting one neuron to the next. These coefficients are called weights.\n",
    "\n",
    "The \"lines\" connect each neuron in a specific layer to all of the neurons on the following. For example, in our example, you can see how each neuron in the hidden layer is connected to a neuron in the output one.\n",
    "\n",
    "Since there are so many __weights__ connecting one layer to the next, we mathematically organize those coefficients in a matrix, denoted as the __weight matrix__.\n",
    "\n",
    "<img src=\"pic2.png\" width=400>\n",
    "\n",
    "Simplified Artificial Neural Network With A Weight Matrix\n",
    "\n",
    "Spoiler:\n",
    "\n",
    "Later you will learn that when we train an artificial neural network, we are actually looking for the best set of weights that will give us a desired outcome. We will not focus on that here, in the context of Linear Algebra.\n",
    "\n",
    "OK! So what does all of this have to do with Linear Algebra?! Lets see!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting The Pieces Together ###\n",
    "\n",
    "In the following videos we use subscripts as well as superscript as a numeric notation for the weight matrix.\n",
    "\n",
    "For example:\n",
    "\n",
    "$W_k$ is weight matrix $k$  \n",
    "$W_{ij}^k$ is the ijij element of weight matrix kk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"middle\"><video width=\"100%\" controls><source src=\"vid1.mp4\" type=\"video/mp4\"></video></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<div align=\"middle\"><video width=\"100%\" controls><source src=\"vid1.mp4\" type=\"video/mp4\"></video></div>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the video introduces a concept we have't mentioned yet, the activation function. No worries, you will learn all about it in the next lesson (Introduction to Neural Networks).\n",
    "\n",
    "When working with neural networks we have 2 primary phases:\n",
    "\n",
    "Training\n",
    "\n",
    "and  \n",
    "\n",
    "Evaluation.  \n",
    "\n",
    "During the training phase, we take the data set (also called the training set), which includes many pairs of inputs and their corresponding targets (outputs). Our goal is to find a set of weights that would best map the inputs to the desired outputs.\n",
    "\n",
    "In the evaluation phase, we use the network that was created in the training phase, apply our new inputs and expect to obtain the desired outputs.\n",
    "\n",
    "The training phase will include two steps:\n",
    "\n",
    "Feedforward  \n",
    "\n",
    "and\n",
    "\n",
    "Backpropagation  \n",
    "\n",
    "We will repeat these steps as many times as we need until we decide that our system has reached the best set of weights, giving us the best possible outputs.\n",
    "\n",
    "To show you how relevant Linear Algebra is here, we will focus on the feedforward process. And again, focus on the mathematical calculations. All of these new definitions (training, evaluation, feedforward, backpropagation, etc will be emphasized very soon!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Feedforward Process- Finding $\\vec{h}$ ###\n",
    "\n",
    "In this section we will look closely at the math behind the feedforward process. With the use of basic Linear Algebra tools, these calculations are pretty simple!\n",
    "\n",
    "Assuming that we have a single hidden layer, we will need two steps in our calculations. The first will be calculating the value of the hidden states and the latter will be calculating the value of the outputs.\n",
    "\n",
    "<img src=\"pic6.png\" width=400>\n",
    "\n",
    "Notice that both the hidden layer and the output layer are displayed as vectors, as they are both represented by more than a single neuron.\n",
    "\n",
    "Our first video will help you understand the first step- __Calculating the value of the hidden states__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"middle\"><video width=\"100%\" controls><source src=\"vid2.mp4\" type=\"video/mp4\"></video></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<div align=\"middle\"><video width=\"100%\" controls><source src=\"vid2.mp4\" type=\"video/mp4\"></video></div>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you saw in the video above, vector $\\vec{h'}$ of the hidden layer will be calculated by multiplying the input vector with the weight matrix $W^{1}$  the following way:  \n",
    "\n",
    "$\\vec{h'} = (\\bar{x} W^1 )$\n",
    "\n",
    "Using vector by matrix multiplication, we can look at this computation the following way:\n",
    "\n",
    "<img src=\"pic7.png\" width=400>\n",
    "\n",
    "After finding $\\vec{h'}$ we need an activation function.  \n",
    "\n",
    "The symbol we use for the activation function is the Greek letter phi: $\\Phi$.  \n",
    "\n",
    "This activation function finalizes the computation of the hidden layer's values.  \n",
    "\n",
    "We can use the following two equations to express the final hidden vector $\\vec{h'}$:  \n",
    "\n",
    "$\\vec{h} = \\Phi(\\vec{x} W^1 )$  \n",
    "\n",
    "or  \n",
    "\n",
    "$\\vec{h} = \\Phi(\\vec{h'})$  \n",
    "\n",
    "Since $W_{ij}$ represents the weight component in the weight matrix, connecting neuron i from the input to neuron j in the hidden layer, we can also write these calculations using a linear combination: (notice that in this example we have n inputs and only 3 hidden neurons)\n",
    "\n",
    "<img src=\"pic8.png\" width=400>\n",
    "\n",
    "More information on the activation functions and how to use them will be found in the next lesson (Introduction to Neural Networks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Feedforward Process- Finding $\\vec{y}$ ###\n",
    "\n",
    "We finished our first step, finding $\\vec{h}$ and now need to find the output $\\vec{y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div align=\"middle\"><video width=\"100%\" controls><source src=\"vid3.mp4\" type=\"video/mp4\"></video></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"<div align=\"middle\"><video width=\"100%\" controls><source src=\"vid3.mp4\" type=\"video/mp4\"></video></div>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you've seen in the video above, the process of calculating the output vector is mathematically similar to that of calculating the vector of the hidden layer. We use, again, a vector by matrix multiplication. The vector is the newly calculated hidden layer and the matrix is the one connecting the hidden layer to the output.\n",
    "\n",
    "<img src=\"pic9.png\" width=300>\n",
    "\n",
    "Essentially, each new layer in an neural network is calculated by a vector by matrix multiplication, where the vector represents the inputs to the new layer and the matrix is the one connecting these new inputs to the next layer.\n",
    "\n",
    "In our example, the input vector is $\\vec{h}$ and the matrix is $W^2$, therefore $\\vec{y}=\\vec{h}W^2$\n",
    "\n",
    "<img src=\"picA.png\" width=500>\n",
    "\n",
    "The video above also generalizes the model we have been taking about.  \n",
    "\n",
    "More on this issue in out next module Neural Networks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env1]",
   "language": "python",
   "name": "conda-env-env1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
